#!/usr/bin/env python3
"""Split Whisper model into obfuscated chunks and generate embedded tail module."""
from __future__ import annotations

import base64
import hashlib
import os
import sys
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from native_config import get_models_dir
from model_manager import get_whisper_model_info

TAIL_SIZE = 30 * 1024
CHUNK_PREFIX = "xcap"
CHUNK_EXT = ".dll"
CHUNK_PAD = 3
CHUNK_DIR = ""
MIN_CHUNK = 100 * 1024 * 1024
MAX_CHUNK = 150 * 1024 * 1024


def _model_path() -> Path:
    info = get_whisper_model_info(get_models_dir())
    return info.path


def _deterministic_rand(seed_bytes: bytes):
    digest = hashlib.sha256(seed_bytes).digest()
    offset = 0
    while True:
        if offset + 8 > len(digest):
            digest = hashlib.sha256(digest).digest()
            offset = 0
        value = int.from_bytes(digest[offset : offset + 8], "big")
        offset += 8
        yield value


def _chunk_sizes(total_body: int, seed: bytes) -> list[int]:
    sizes = []
    remaining = total_body
    rand_iter = _deterministic_rand(seed)
    while remaining > 0:
        if remaining <= MAX_CHUNK:
            size = remaining
        else:
            span = MAX_CHUNK - MIN_CHUNK + 1
            size = MIN_CHUNK + (next(rand_iter) % span)
            if remaining - size < MIN_CHUNK:
                size = remaining
        sizes.append(size)
        remaining -= size
    return sizes


def _write_tail_module(
    target: Path,
    *,
    tail_b64: str,
    model_size: int,
    model_sha256: str,
    chunk_count: int,
    chunk_names: list[str],
    chunk_dir: str,
) -> None:
    content = f"""# Auto-generated by scripts/build_whisper_model_obfuscation.py
TAIL_B64 = {tail_b64!r}
TAIL_SIZE = {TAIL_SIZE}
MODEL_SIZE = {model_size}
MODEL_SHA256 = {model_sha256!r}
CHUNK_PREFIX = {CHUNK_PREFIX!r}
CHUNK_EXT = {CHUNK_EXT!r}
CHUNK_PAD = {CHUNK_PAD}
CHUNK_COUNT = {chunk_count}
CHUNK_NAMES = {chunk_names!r}
CHUNK_DIR = {chunk_dir!r}
"""
    target.write_text(content, encoding="utf-8")


def main() -> int:
    model_path = _model_path()
    if not model_path.exists():
        print(f"Model not found: {model_path}")
        return 1

    size = model_path.stat().st_size
    if size <= TAIL_SIZE:
        print("Model file is too small.")
        return 1

    with model_path.open("rb") as handle:
        handle.seek(0, os.SEEK_END)
        total_size = handle.tell()
        handle.seek(total_size - TAIL_SIZE)
        tail = handle.read(TAIL_SIZE)

    tail_b64 = base64.urlsafe_b64encode(tail).decode("ascii").rstrip("=")
    model_sha256 = hashlib.sha256(model_path.read_bytes()).hexdigest()

    body_size = total_size - TAIL_SIZE
    seed = model_path.name.encode("utf-8")
    sizes = _chunk_sizes(body_size, seed)

    # Generate hashed chunk names (16 hex + .dll)
    chunk_names: list[str] = []
    for idx in range(1, len(sizes) + 1):
        digest = hashlib.sha256(model_sha256.encode("utf-8") + idx.to_bytes(4, "big")).hexdigest()[:16]
        chunk_names.append(f".{digest}{CHUNK_EXT}")

    # Split into chunk files
    chunk_dir = (CHUNK_DIR or "").strip()
    parent = model_path.parent
    if parent.name == "whisper" and parent.parent.name == "models":
        model_root = parent.parent
    else:
        model_root = parent
    target_dir = model_root if not chunk_dir else (model_root / chunk_dir)
    target_dir.mkdir(parents=True, exist_ok=True)

    # Remove old sequential chunks in whisper folder (xcap*.dll)
    for legacy in model_path.parent.glob(f"{CHUNK_PREFIX}*{CHUNK_EXT}"):
        try:
            legacy.unlink()
        except Exception:
            pass

    with model_path.open("rb") as handle:
        for idx, chunk_size in enumerate(sizes, start=1):
            chunk_path = target_dir / chunk_names[idx - 1]
            with chunk_path.open("wb") as out:
                remaining = chunk_size
                while remaining > 0:
                    data = handle.read(min(1024 * 1024, remaining))
                    if not data:
                        break
                    out.write(data)
                    remaining -= len(data)

    # Write tail module with chunk count
    module_path = Path(__file__).resolve().parents[1] / "native_whisper_model_tail.py"
    _write_tail_module(
        module_path,
        tail_b64=tail_b64,
        model_size=total_size,
        model_sha256=model_sha256,
        chunk_count=len(sizes),
        chunk_names=chunk_names,
        chunk_dir=chunk_dir,
    )

    # Remove original model
    model_path.unlink(missing_ok=True)

    print(f"Wrote {len(sizes)} chunks and embedded tail module to {module_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
